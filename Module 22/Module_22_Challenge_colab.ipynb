{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21590,"status":"ok","timestamp":1681183091349,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"a_KW73O2e3dw","outputId":"dba04330-9510-407a-eadc-1e3730906df3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Waiting for headers] [C\r                                                                               \rHit:2 http://security.ubuntu.com/ubuntu focal-security InRelease\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to ppa.launc\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to ppa.launc\r                                                                               \r0% [Waiting for headers] [Waiting for headers]\r                                              \rHit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n","Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n","Hit:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n","Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n","Hit:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n","Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n","Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n","Hit:11 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n","Reading package lists... Done\n"]}],"source":["import os\n","# Find the latest version of spark 3.x  from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.3.1'\n","spark_version = 'spark-3.3.2'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5826,"status":"ok","timestamp":1681183102352,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"2XbWNf1Te5fM"},"outputs":[],"source":["# Import packages\n","from pyspark.sql import SparkSession\n","import time\n","\n","# Create a SparkSession\n","spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":447,"status":"ok","timestamp":1681183103455,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"wOJqxG_RPSwp"},"outputs":[],"source":["# 1. Read in the AWS S3 bucket into a DataFrame.\n","from pyspark import SparkFiles\n","url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9531,"status":"ok","timestamp":1681183514363,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"_HVvvfz-WGqy","outputId":"31f00ceb-d5b2-4534-8dcd-214f4d3337e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+-------------------+----------+------+--------+---------+-----------+--------+------+----------+----+\n","|                  id|               date|date_built| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|\n","+--------------------+-------------------+----------+------+--------+---------+-----------+--------+------+----------+----+\n","|f8a53099-ba1c-47d...|2022-04-08 00:00:00|      2016|936923|       4|        3|       3167|   11733|     2|         1|  76|\n","|7530a2d8-1ae3-451...|2021-06-13 00:00:00|      2013|379628|       2|        2|       2235|   14384|     1|         0|  23|\n","|43de979c-0bf0-4c9...|2019-04-12 00:00:00|      2014|417866|       2|        2|       2127|   10575|     2|         0|   0|\n","|b672c137-b88c-48b...|2019-10-16 00:00:00|      2016|239895|       2|        2|       1631|   11149|     2|         0|   0|\n","|e0726d4d-d595-407...|2022-01-08 00:00:00|      2017|424418|       3|        2|       2249|   13878|     2|         0|   4|\n","|5aa00529-0533-46b...|2019-01-30 00:00:00|      2017|218712|       2|        3|       1965|   14375|     2|         0|   7|\n","|131492a1-72e2-4a8...|2020-02-08 00:00:00|      2017|419199|       2|        3|       2062|    8876|     2|         0|   6|\n","|8d54a71b-c520-44e...|2019-07-21 00:00:00|      2010|323956|       2|        3|       1506|   11816|     1|         0|  25|\n","|e81aacfe-17fe-46b...|2020-06-16 00:00:00|      2016|181925|       3|        3|       2137|   11709|     2|         0|  22|\n","|2ed8d509-7372-46d...|2021-08-06 00:00:00|      2015|258710|       3|        3|       1918|    9666|     1|         0|  25|\n","|f876d86f-3c9f-42b...|2019-02-27 00:00:00|      2011|167864|       3|        3|       2471|   13924|     2|         0|  15|\n","|0a2bd445-8508-4d8...|2021-12-30 00:00:00|      2014|337527|       2|        3|       1926|   12556|     1|         0|  23|\n","|941bad30-eb49-4a7...|2020-05-09 00:00:00|      2015|229896|       3|        3|       2197|    8641|     1|         0|   3|\n","|dd61eb34-6589-4c0...|2021-07-25 00:00:00|      2016|210247|       3|        2|       1672|   11986|     2|         0|  28|\n","|f1e4cef7-d151-439...|2019-02-01 00:00:00|      2011|398667|       2|        3|       2331|   11356|     1|         0|   7|\n","|ea620c7b-c2f7-4c6...|2021-05-31 00:00:00|      2011|437958|       3|        3|       2356|   11052|     1|         0|  26|\n","|f233cb41-6f33-4b0...|2021-07-18 00:00:00|      2016|437375|       4|        3|       1704|   11721|     2|         0|  34|\n","|c797ca12-52cd-4b1...|2019-06-08 00:00:00|      2015|288650|       2|        3|       2100|   10419|     2|         0|   7|\n","|0cfe57f3-28c2-472...|2019-10-04 00:00:00|      2015|308313|       3|        3|       1960|    9453|     2|         0|   2|\n","|4566cd2a-ac6e-435...|2019-07-15 00:00:00|      2016|177541|       3|        3|       2130|   10517|     2|         0|  25|\n","+--------------------+-------------------+----------+------+--------+---------+-----------+--------+------+----------+----+\n","only showing top 20 rows\n","\n"]}],"source":["spark.sparkContext.addFile(url)\n","home_df = spark.read.csv(SparkFiles.get(\"home_sales_revised.csv\"), sep=\",\", header=True, inferSchema=True)\n","home_df.show()"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":482,"status":"ok","timestamp":1681183518068,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"RoljcJ7WPpnm"},"outputs":[],"source":["# 2. Create a temporary view of the DataFrame.\n","\n","home_df.createOrReplaceTempView('home_sales')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1667,"status":"ok","timestamp":1681183554332,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"L6fkwOeOmqvq","outputId":"c4770637-d156-4318-8544-1c29fe69ba77"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+-------------+\n","|bedrooms|average_price|\n","+--------+-------------+\n","|       4|    299661.01|\n","+--------+-------------+\n","\n"]}],"source":["# 3. What is the average price for a four bedroom house sold in each year rounded to two decimal places?\n","\n","question1 = \"\"\"\n","(SELECT bedrooms, ROUND(avg(price),2) as average_price\n","FROM home_sales\n","WHERE bedrooms == 4\n","GROUP BY bedrooms)\n","\"\"\"\n","\n","spark.sql(question1).show()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1011,"status":"ok","timestamp":1681183577278,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"l8p_tUS8h8it","outputId":"34e90877-30d0-4503-e35d-15e97f255dda"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+-------------+\n","|date_built|average_price|\n","+----------+-------------+\n","|      2010|    292859.62|\n","|      2011|    291117.47|\n","|      2012|    293683.19|\n","|      2013|    295962.27|\n","|      2014|    290852.27|\n","|      2015|     288770.3|\n","|      2016|    290555.07|\n","|      2017|    292676.79|\n","+----------+-------------+\n","\n"]}],"source":["# 4. What is the average price of a home for each year the home was built that have 3 bedrooms and 3 bathrooms rounded to two decimal places?\n","\n","question2 = \"\"\"\n","(SELECT date_built, ROUND(avg(price),2) as average_price\n","FROM home_sales\n","WHERE bedrooms==3 AND bathrooms==3\n","GROUP BY date_built\n","ORDER BY date_built ASC)\n","\"\"\"\n","\n","spark.sql(question2).show()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1065,"status":"ok","timestamp":1681183601187,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"Y-Eytz64liDU","outputId":"39fb69a0-2d28-4243-b86e-56e29132313e"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+-------------+\n","|date_built|average_price|\n","+----------+-------------+\n","|      2010|    285010.22|\n","|      2011|    276553.81|\n","|      2012|    307539.97|\n","|      2013|    303676.79|\n","|      2014|    298264.72|\n","|      2015|    297609.97|\n","|      2016|     293965.1|\n","|      2017|    280317.58|\n","+----------+-------------+\n","\n"]}],"source":["# 5. What is the average price of a home for each year built that have 3 bedrooms, 3 bathrooms, with two floors,\n","# and are greater than or equal to 2,000 square feet rounded to two decimal places?\n","\n","question3 = \"\"\"\n","(SELECT date_built, ROUND(avg(price),2) as average_price\n","FROM home_sales\n","WHERE bedrooms==3 AND bathrooms==3 AND floors==2 AND sqft_living>=2000\n","GROUP BY date_built\n","ORDER BY date_built ASC)\n","\"\"\"\n","\n","spark.sql(question3).show()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1219,"status":"ok","timestamp":1681183667067,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"GUrfgOX1pCRd","outputId":"04c573f1-a8e2-4f2b-d276-074c4f4eb6c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----+-------------+\n","|view|average_price|\n","+----+-------------+\n","|   0|    403848.51|\n","|   1|    401044.25|\n","|   2|    397389.25|\n","|   3|     398867.6|\n","|   4|    399631.89|\n","|   5|    401471.82|\n","|   6|    395655.38|\n","|   7|    403005.77|\n","|   8|    398592.71|\n","|   9|    401393.34|\n","|  10|    401868.43|\n","|  11|    399548.12|\n","|  12|    401501.32|\n","|  13|    398917.98|\n","|  14|    398570.03|\n","|  15|     404673.3|\n","|  16|    399586.53|\n","|  17|    398474.49|\n","|  18|    399332.91|\n","|  19|    398953.17|\n","+----+-------------+\n","only showing top 20 rows\n","\n","--- 0.7618575096130371 seconds ---\n"]}],"source":["# 6. What is the \"view\" rating for the average price of a home, rounded to two decimal places, where the homes are greater than\n","# or equal to $350,000? Although this is a small dataset, determine the run time for this query.\n","\n","start_time = time.time()\n","\n","question4 = \"\"\"\n","(SELECT view, ROUND(avg(price),2) as average_price\n","FROM home_sales\n","WHERE price>=350000\n","GROUP BY view\n","ORDER BY view ASC)\n","\"\"\"\n","\n","spark.sql(question4).show()\n","\n","\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1976,"status":"ok","timestamp":1681183683781,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"KAhk3ZD2tFy8","outputId":"5c5c88dd-a352-43ed-923c-2939868fb7cb"},"outputs":[{"data":{"text/plain":["DataFrame[]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# 7. Cache the the temporary table home_sales.\n","spark.sql(\"cache table home_sales\")\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":154,"status":"ok","timestamp":1681183701071,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"4opVhbvxtL-i","outputId":"68f79724-e982-4242-8589-58ea9193b2c3"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# 8. Check if the table is cached.\n","spark.catalog.isCached('home_sales')"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":680,"status":"ok","timestamp":1681183743134,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"5GnL46lwTSEk","outputId":"533fdb4f-32fd-4c40-e10a-7db0df6c96e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----+-------------+\n","|view|average_price|\n","+----+-------------+\n","|   0|    403848.51|\n","|   1|    401044.25|\n","|   2|    397389.25|\n","|   3|     398867.6|\n","|   4|    399631.89|\n","|   5|    401471.82|\n","|   6|    395655.38|\n","|   7|    403005.77|\n","|   8|    398592.71|\n","|   9|    401393.34|\n","|  10|    401868.43|\n","|  11|    399548.12|\n","|  12|    401501.32|\n","|  13|    398917.98|\n","|  14|    398570.03|\n","|  15|     404673.3|\n","|  16|    399586.53|\n","|  17|    398474.49|\n","|  18|    399332.91|\n","|  19|    398953.17|\n","+----+-------------+\n","only showing top 20 rows\n","\n","--- 0.3863053321838379 seconds ---\n"]}],"source":["# 9. Using the cached data, run the query that filters out the view ratings with average price \n","#  greater than or equal to $350,000. Determine the runtime and compare it to uncached runtime.\n","\n","start_time = time.time()\n","\n","question5 = \"\"\"\n","(SELECT view, ROUND(avg(price),2) as average_price\n","FROM home_sales\n","WHERE price>=350000\n","GROUP BY view\n","ORDER BY view ASC)\n","\"\"\"\n","\n","spark.sql(question5).show()\n","\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3302,"status":"ok","timestamp":1681183764362,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"Qm12WN9isHBR"},"outputs":[],"source":["# 10. Partition by the \"date_built\" field on the formatted parquet home sales data \n","home_df.write.partitionBy(\"date_built\").mode(\"overwrite\").parquet(\"homesales_partitioned\")\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":763,"status":"ok","timestamp":1681183782748,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"AZ7BgY61sRqY"},"outputs":[],"source":["# 11. Read the parquet formatted data.\n","p_df_p=spark.read.parquet('homesales_partitioned')"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":133,"status":"ok","timestamp":1681183802306,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"J6MJkHfvVcvh"},"outputs":[],"source":["# 12. Create a temporary table for the parquet data.\n","p_df_p.createOrReplaceTempView('p_homesales_p')"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1376,"status":"ok","timestamp":1681183945888,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"G_Vhb52rU1Sn","outputId":"c9292e07-238a-43eb-9edd-035c716957c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----+-------------+\n","|view|average_price|\n","+----+-------------+\n","|   0|    403848.51|\n","|   1|    401044.25|\n","|   2|    397389.25|\n","|   3|     398867.6|\n","|   4|    399631.89|\n","|   5|    401471.82|\n","|   6|    395655.38|\n","|   7|    403005.77|\n","|   8|    398592.71|\n","|   9|    401393.34|\n","|  10|    401868.43|\n","|  11|    399548.12|\n","|  12|    401501.32|\n","|  13|    398917.98|\n","|  14|    398570.03|\n","|  15|     404673.3|\n","|  16|    399586.53|\n","|  17|    398474.49|\n","|  18|    399332.91|\n","|  19|    398953.17|\n","+----+-------------+\n","only showing top 20 rows\n","\n","--- 1.2515435218811035 seconds ---\n"]}],"source":["# 13. Run the query that filters out the view ratings with average price of greater than or equal to $350,000 \n","# with the parquet DataFrame. Round your average to two decimal places. \n","# Determine the runtime and compare it to the cached version.\n","\n","start_time = time.time()\n","\n","query = \"\"\"\n","  SELECT view, ROUND(AVG(price), 2) AS average_price \n","  FROM p_homesales_p \n","  WHERE price >= 350000 \n","  GROUP BY view \n","  ORDER BY view\n","\"\"\"\n","spark.sql(query).show()\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":358},"executionInfo":{"elapsed":324,"status":"error","timestamp":1681184240104,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"hjjYzQGjtbq8","outputId":"37cb81d8-224d-4ec9-b995-a20071017801"},"outputs":[{"ename":"AnalysisException","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-8e3a0ca70d5e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 14. Uncache the home_sales temporary table.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UNCACHE TABLE homesales\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0msqlQuery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: homesales; line 1 pos 14;\n'UncacheTable false, false\n+- 'UnresolvedRelation [homesales], [], false\n"]}],"source":["# 14. Uncache the home_sales temporary table.\n","spark.sql(\"UNCACHE TABLE homesales\")"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"elapsed":231,"status":"error","timestamp":1681184235322,"user":{"displayName":"K","userId":"16208636433329242454"},"user_tz":300},"id":"Sy9NBvO7tlmm","outputId":"b21d46d6-25a7-4434-9838-670fab9b6c8d"},"outputs":[{"ename":"AnalysisException","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-9f7f1c4f4c90>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 15. Check if the home_sales is no longer cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misCached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"homesales\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/pyspark/sql/catalog.py\u001b[0m in \u001b[0;36misCached\u001b[0;34m(self, tableName)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misCached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;34m\"\"\"Returns true if the table is currently cached in-memory.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misCached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtableName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: homesales;\n'UnresolvedRelation [homesales], [], false\n"]}],"source":["# 15. Check if the home_sales is no longer cached\n","spark.catalog.isCached(\"homesales\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Si-BNruRUGK3"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1F1iPJq9N1HJt9hP37jwdTlfAOPvBQgRm","timestamp":1681184511972}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.7.7 ('PythonData')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"nteract":{"version":"0.28.0"},"vscode":{"interpreter":{"hash":"87bec44227f665cd1a12a912a3fe129cb1795a5babfd21638bc00827218663c0"}}},"nbformat":4,"nbformat_minor":0}
